{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import beta as betaP\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# enable validation (e.g. validate parameters of distributions)\n",
    "assert pyro.__version__.startswith('0.3.1')\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs of lable 1: 0.325\n",
      "\t lable 2: 0.30833333333333335\n",
      "\t lable 3: 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "iris_df = pd.read_csv('iris.csv', sep=',')\n",
    "x_train, x_test, y_train, y_test =  train_test_split(iris_df, iris_df[iris_df.columns[4]], test_size=0.2)\n",
    "\n",
    "labl1 = len(x_train[x_train.class_dataset == 1])\n",
    "labl2 = len(x_train[x_train.class_dataset == 2])\n",
    "labl3 = len(x_train[x_train.class_dataset == 3])\n",
    "\n",
    "print(\"Probs of lable 1: \" + str(labl1/len(y_train)) + \"\\n\\t lable 2: \" + str(labl2/len(y_train)) + \"\\n\\t lable 3: \" + str(labl3/len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.006     , 0.34894699],\n",
       "        [3.418     , 0.37719491],\n",
       "        [1.464     , 0.17176728],\n",
       "        [0.244     , 0.10613199]],\n",
       "\n",
       "       [[5.936     , 0.51098337],\n",
       "        [2.77      , 0.31064449],\n",
       "        [4.26      , 0.46518813],\n",
       "        [1.326     , 0.19576517]],\n",
       "\n",
       "       [[6.588     , 0.62948868],\n",
       "        [2.974     , 0.31925538],\n",
       "        [5.552     , 0.54634787],\n",
       "        [2.026     , 0.27188968]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num = 3\n",
    "attribute_num = 4\n",
    "count = iris_df.shape[0]\n",
    "mi_result = np.empty((class_num, attribute_num))\n",
    "sigma_result = np.empty((class_num, attribute_num))\n",
    "\n",
    "pair_m_s4class = np.zeros(((class_num, attribute_num, 2)))\n",
    "\n",
    "for i in range(class_num):\n",
    "    for j in range(attribute_num):\n",
    "        pair_m_s4class[i][j][0] = np.mean(iris_df.iloc[i*50:(i+1)*50, j])\n",
    "        pair_m_s4class[i][j][1] = np.std(iris_df.iloc[i*50:(i+1)*50, j])\n",
    "\n",
    "pair_m_s4class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.24      , 1.79844377],\n",
       "       [2.1       , 1.67092789],\n",
       "       [2.08      , 1.63878003],\n",
       "       [2.08      , 1.57657857]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_m_s4attribute = np.zeros((attribute_num, 2))\n",
    "\n",
    "for i in range(attribute_num):\n",
    "    pair_m_s4attribute[i][0] = np.mean(iris_df.iloc[i])\n",
    "    pair_m_s4attribute[i][1] = np.std(iris_df.iloc[i])\n",
    "\n",
    "pair_m_s4attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data): \n",
    "    mi = pyro.sample('mi' , dist.Normal(2., 1.5))   \n",
    "    sigma = pyro.sample('sigma' , dist.Uniform(0., 10.))    \n",
    "    with pyro.plate('data', len(data)):\n",
    "        data_obs = torch.from_numpy(data.values.astype(np.float)).type(torch.FloatTensor) \n",
    "        pyro.sample(\"obs\", dist.Normal(mi,  sigma) , obs = data_obs)    \n",
    "\n",
    "def guide(data):  \n",
    "    mi_loc =pyro.param('mi_loc', torch.tensor(0.))\n",
    "    mi_scale = pyro.param('mi_scale', torch.tensor(1.), constraint=constraints.positive)  \n",
    "    \n",
    "    sigma_loc = pyro.param('sigma_loc', torch.tensor(1.),  constraint=constraints.positive)\n",
    "    sigma_scale = pyro.param('sigma_scale', torch.tensor(0.05),  constraint=constraints.positive) \n",
    "    \n",
    "    mi = pyro.sample('mi', dist.Normal(mi_loc, mi_scale))\n",
    "    sigma = pyro.sample('sigma', dist.Normal(sigma_loc, sigma_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations= 3000\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.01})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=data.shape[0])\n",
    "    t=tqdm(range(num_iterations))\n",
    "    losses = []\n",
    "    for j in range(num_iterations):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "    return (svi, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554970b4bc624596aed2b0d15de90fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7544, requires_grad=True)\n",
      "tensor(0.9739, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b584c0e5094ffdae81677e525397af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3207, requires_grad=True)\n",
      "tensor(0.3820, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102c936799af4067854ed87296ac8755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4684, requires_grad=True)\n",
      "tensor(0.1679, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be725c126d443b3826c1e8ff7a2d811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2345, requires_grad=True)\n",
      "tensor(0.1149, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3542d074dd438bbc567ea283c742fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9418, requires_grad=True)\n",
      "tensor(0.5671, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdec1ff5f7549dbbf555be8d18b4fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7348, requires_grad=True)\n",
      "tensor(0.3315, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87afc3f8d19846c782d2902c26693b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2162, requires_grad=True)\n",
      "tensor(0.4923, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8a08cf4d844d14a68e97bd1841e584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3172, requires_grad=True)\n",
      "tensor(0.2085, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39feb0010adf4ea08bf57614f5860725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5113, requires_grad=True)\n",
      "tensor(0.6663, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5797fd9fc5847ee946defbebcf0d64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9462, requires_grad=True)\n",
      "tensor(0.3095, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055cddec14514d6cb4e2c8ab902ce48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5563, requires_grad=True)\n",
      "tensor(0.6129, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705699db2b3f4b9f90344933cab9ad66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0283, requires_grad=True)\n",
      "tensor(0.3045, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(class_num):\n",
    "    for j in range(attribute_num):\n",
    "        dataz = x_train[x_train.class_dataset == i+1]\n",
    "        dataz = dataz[dataz.columns[j]]\n",
    "        svi, loss = train(dataz)\n",
    "        posterior = svi.run(dataz)        \n",
    "        mi_result[i, j] = pyro.param(\"mi_loc\").item()\n",
    "        sigma_result[i, j] = pyro.param(\"sigma_loc\").item()\n",
    "        print(pyro.param(\"mi_loc\"))\n",
    "        print(pyro.param(\"sigma_loc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataz = torch.cat((torch.zeros(labl1), torch.ones(labl2), torch.empty(labl3).fill_(2.)))\n",
    "dataz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelz(data):\n",
    "    alpha = torch.tensor(6.0)\n",
    "    beta = torch.tensor(10.0)\n",
    "    lable_probs = pyro.sample('lable_probs', dist.Beta(alpha, beta).expand([3]).independent(1))\n",
    "    normalized_lable_probs = lable_probs / torch.sum(lable_probs)\n",
    "\n",
    "    with pyro.plate('data', len(data)):\n",
    "        pyro.sample('obs', dist.Categorical(probs=normalized_lable_probs), obs=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guidez(data):\n",
    "    alphas = pyro.param('alphas', torch.tensor(6.).expand([3]), constraint=constraints.positive)\n",
    "    betas = pyro.param('betas', torch.tensor(10.).expand([3]), constraint=constraints.positive) \n",
    "\n",
    "    pyro.sample('lable_probs', dist.Beta(alphas, betas).independent(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030fef0026c34352a8ab5d04669790ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.3293001055717468, 2:0.3170788288116455, 3:0.35362106561660767\n"
     ]
    }
   ],
   "source": [
    "# def print_progress():\n",
    "#     alphas = pyro.param(\"alphas\")\n",
    "#     betas = pyro.param(\"betas\")\n",
    "    \n",
    "#     print(alphas)\n",
    "#     print(betas)\n",
    "        \n",
    "# adam_params = {\"lr\": 0.0005}\n",
    "# optimizer = pyro.optim.Adam(adam_params)\n",
    "# svi = SVI(model, guide, optimizer, loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "# n_steps = 2501\n",
    "# for step in range(n_steps):\n",
    "#     svi.step(dataz)\n",
    "#     if step % 100 == 0:\n",
    "#         print_progress()\n",
    "def train(data):\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations= 3000\n",
    "    optimz = pyro.optim.Adam({\"lr\": 0.001})\n",
    "    svi = pyro.infer.SVI(modelz, guidez, optimz, loss=pyro.infer.Trace_ELBO(), num_samples=data.shape[0])\n",
    "    t=tqdm(range(num_iterations))\n",
    "    losses = []\n",
    "    for j in range(num_iterations):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "    return (svi, losses)\n",
    "\n",
    "lable_probabs = np.ones(3)\n",
    "svi, loss = train(dataz)\n",
    "\n",
    "alphas = pyro.param(\"alphas\")\n",
    "betas = pyro.param(\"betas\")\n",
    "means = alphas / (alphas + betas)\n",
    "normalized_means = means / torch.sum(means)\n",
    "for i in range(3):\n",
    "    lable_probabs[i] = normalized_means[i].double()\n",
    "print(\"1: \" + str(lable_probabs[0]) + \", 2:\" + str(lable_probabs[1]) + \", 3:\" + str(lable_probabs[2]))\n",
    "\n",
    "# adam_params = {\"lr\": 0.0005}\n",
    "# optimizer = pyro.optim.Adam(adam_params)\n",
    "# svi = SVI(model, guide, optimizer, loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "# n_steps = 2501\n",
    "# for step in range(n_steps):\n",
    "#     svi.step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normpdf(x, mean, sd):\n",
    "    var = float(sd)**2\n",
    "    denom = (2*math.pi*var)**.5\n",
    "    num = math.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "    return num/denom\n",
    "\n",
    "def get_max(array):\n",
    "    return list(array).index(np.max(array))+1\n",
    "\n",
    "def get_result(test_row):\n",
    "    result = lable_probabs.copy()\n",
    "    for i in range(class_num):\n",
    "        for j in range(attribute_num):\n",
    "            result[i] *= normpdf(test_row[j], mi_result[i][j], sigma_result[i][j])\n",
    "    return get_max(result)\n",
    "\n",
    "def get_results4test(test):\n",
    "    result = []\n",
    "    for i in range(len(test)):\n",
    "        result.append(get_result(test.iloc[i, :].values))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 1 3 2 3 1 1 3 2 1 3 2 2 1 2 2 1 1 2 2 3 1 3 2 1 1 2 3]\n",
      "[1 2 2 1 3 2 3 1 1 3 2 1 3 2 2 1 2 2 1 1 2 2 2 1 3 2 1 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "x = get_results4test(x_test)\n",
    "print(np.array(x))\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.values, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
